---
title: "Tracking Selection in Bees with ABC-RF"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r clean cache, echo=TRUE, eval=FALSE, include=TRUE}
rm(list=ls())
ls()
```

## ABC random forests analysis

#### Install required packages
```{r install packages, echo=TRUE}
#install.packages(c("DataExplorer", 
#                   "abcrf",
#                   "weights",
#                   "grDevices",
#                   "gplots",
#                   "viridis"),
#                 dependencies = T)
```

#### Load packages and source file
```{r load packages, echo=TRUE, eval=FALSE, include=TRUE}
library(DataExplorer)
library(abcrf)
library(weights)
library(grDevices)
library(gplots)
library(viridis)
library(gtools)
```

#### Upload the RF training reference table files
```{r load superbatch 1, echo=TRUE, eval=FALSE, include=TRUE}
# MUSE 2 - Super-batch 1
load("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/Cluster_data/muse/tracking-selection-bees-2/results/pooled_reftable_2.RData")
pooled_raw_reftable_1 <- pooled_raw_reftable
rm(pooled_raw_reftable)
```

```{r load superbatch 2, echo=TRUE, eval=FALSE, include=TRUE}
# MUSE 3 - Super-batch 2
load("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/Cluster_data/muse/tracking-selection-bees-3/results/pooled_reftable_3.RData")
pooled_raw_reftable_2 <- pooled_raw_reftable
rm(pooled_raw_reftable)
```

```{r load superbatch 3, echo=TRUE, eval=FALSE, include=TRUE}
# MUSE 4 - Super-batch 3
load("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/Cluster_data/muse/tracking-selection-bees-4/results/pooled_reftable_4.RData")
pooled_raw_reftable_3 <- pooled_raw_reftable
rm(pooled_raw_reftable)
```

```{r load superbatch 4, echo=TRUE, eval=FALSE, include=TRUE}
# MUSE 5 - Super-batch 4
load("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/Cluster_data/muse/tracking-selection-bees-5/results/pooled_reftable_5.RData")
pooled_raw_reftable_4 <- pooled_raw_reftable
rm(pooled_raw_reftable)
```

```{r load superbatch 5, echo=TRUE, eval=FALSE, include=TRUE}
# OSC 1 - Super-batch 5
load("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/Cluster_data/osc/tracking-selection-bees-6/results/pooled_reftable_6.RData")
pooled_raw_reftable_5 <- pooled_raw_reftable
rm(pooled_raw_reftable)
```

#### Pool together the reftables from super-batches
```{r pooling reftable, echo=TRUE, eval=FALSE, include=TRUE}
pooled_raw_reftable_bees_total <- rbind(pooled_raw_reftable_1,
                                        pooled_raw_reftable_2,
                                        pooled_raw_reftable_3,
                                        pooled_raw_reftable_4,
                                        pooled_raw_reftable_5
                                       )

rm(pooled_raw_reftable_1)
rm(pooled_raw_reftable_2)
rm(pooled_raw_reftable_3)
rm(pooled_raw_reftable_4)
rm(pooled_raw_reftable_5)

#save(pooled_raw_reftable_bees_total, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_total_",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_total",".RData"))
```

#### Prepare the training RF reftable
```{r training data preparation, echo=TRUE, eval=FALSE, include=TRUE}

## AVALON POPULATION
##-------------------------------------

# Take only the parameters and variables
pooled_raw_reftable_bees_avalon <- pooled_raw_reftable_bees_total[,-c(408:2135)]

#save(pooled_raw_reftable_bees_avalon, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_avalon",".RData"))

# Check missing data
plot_missing(pooled_raw_reftable_bees_avalon) 
missing_count_ava <- sapply(pooled_raw_reftable_bees_avalon, function(x) sum(is.na(x)))

# produce a data.frame with only summary statistics that contain missing values higher than a threshold
pooled_reftable_bees_avalon <- pooled_raw_reftable_bees_avalon[,missing_count_ava < nrow(pooled_raw_reftable_bees_avalon)/2]

# remove also POPSelSd, SAMSelSd, FSTfdr* and locus-specific summary stats columns
pooled_reftable_bees_avalon <- pooled_reftable_bees_avalon[,-c(123:124, # POPSelMean and POPSelSd
                                                               126:127, # POPStrongSelMean and POPStrongSelSd
                                                               129:130, # SAMSelMean and SAMSelSd
                                                               132:133, # SAMStrongSelMean and SAMStrongSelSd
                                                               134:138, # FSTfdrNS
                                                               139:167)]# LSS and WSSs 

# check it!
missing_count_ava <- sapply(pooled_reftable_bees_avalon, function(x) sum(is.na(x)))
plot_missing(pooled_reftable_bees_avalon) 

# remove remaining rows with missing data
pooled_reftable_bees_avalon <- pooled_reftable_bees_avalon[complete.cases(pooled_reftable_bees_avalon), ]

# check it again
plot_missing(pooled_reftable_bees_avalon)
table(missing_count_ava <- sapply(pooled_reftable_bees_avalon, function(x) sum(is.na(x))))

# Check != numeric values
table(infinite_count_ava <- sapply(pooled_reftable_bees_avalon, function(x) sum(is.infinite(x))))

# check the number of rows and columns of the final reference table
dim(pooled_reftable_bees_avalon)
# 13953   287

#save(pooled_reftable_bees_avalon, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_reftable_bees_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6/pooled_reftable_bees_avalon",".RData"))

# Prepare the global summary statistics table by removing columns that do not contain summary stats
global_sumstats4training_avalon <- pooled_reftable_bees_avalon[, -c(1:125)]

# check the number of rows and columns of the final global summary stats table
dim(global_sumstats4training_avalon)
# 13953   162

#save(global_sumstats4training_avalon, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/global_sumstats4training_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/global_sumstats4training_avalon",".RData"))

## PLACERITA POPULATION
##-------------------------------------

# Take only the parameters and variables
#pooled_raw_reftable_bees_total[, grepl("^_Pla", names(pooled_raw_reftable_bees_total))]
pooled_raw_reftable_bees_placerita <- pooled_raw_reftable_bees_total[,-c(120:1847)]

#save(pooled_raw_reftable_bees_placerita, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_raw_reftable_bees_placerita",".RData"))

# Check missing data
plot_missing(pooled_raw_reftable_bees_placerita) 
missing_count_pla <- sapply(pooled_raw_reftable_bees_placerita, function(x) sum(is.na(x)))

# produce a data.frame with only summary statistics that contain missing values higher than a threshold
pooled_reftable_bees_placerita <- pooled_raw_reftable_bees_placerita[,missing_count_pla < nrow(pooled_raw_reftable_bees_placerita)/2]

# remove also POPSelSd, SAMSelSd, FSTfdr* and locus-specific summary stats columns
pooled_reftable_bees_placerita <- pooled_reftable_bees_placerita[,-c(123:124, # POPSelMean and POPSelSd
                                                                     126:127, # POPStrongSelMean and POPStrongSelSd
                                                                     129, # SAMSelMean and SAMSelSd
                                                                     131:132, # SAMStrongSelMean and SAMStrongSelSd
                                                                     133:137, # FSTfdrNS
                                                                     138:166)]# LSS and WSSs 

# check it!
missing_count_pla <- sapply(pooled_reftable_bees_placerita, function(x) sum(is.na(x)))
plot_missing(pooled_reftable_bees_placerita) 

# remove remaining rows with missing data
pooled_reftable_bees_placerita <- pooled_reftable_bees_placerita[complete.cases(pooled_reftable_bees_placerita), ]

# check it again
plot_missing(pooled_reftable_bees_placerita)
table(missing_count_pla <- sapply(pooled_reftable_bees_placerita, function(x) sum(is.na(x))))

# Check != numeric values
table(infinite_count_pla <- sapply(pooled_reftable_bees_placerita, function(x) sum(is.infinite(x))))

# check the number of rows and columns of the final reference table
dim(pooled_reftable_bees_placerita)
# 14125   287

#save(pooled_reftable_bees_placerita, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/pooled_reftable_bees_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6/pooled_reftable_bees_placerita",".RData"))

# Prepare the global summary statistics table by removing columns that do not contain summary stats
global_sumstats4training_placerita <- pooled_reftable_bees_placerita[, -c(1:125)]

# check the number of rows and columns of the final global summary stats table
dim(global_sumstats4training_placerita)
# 14125   162

#save(global_sumstats4training_placerita, 
#     file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/global_sumstats4training_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/global_sumstats4training_placerita",".RData"))
```

#### Prepare the DATA reftable
```{r fixedpods data preparation, echo=TRUE, eval=FALSE, include=TRUE}

## AVALON POPULATION
##-----------------------------

# global summary stats reftable
load("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/avalon_globalStats_reftable.RData")

global_Obssumstats_avalon <- data2globalStats

global_Obssumstats_avalon <- global_Obssumstats_avalon[, names(global_Obssumstats_avalon) %in% names(global_sumstats4training_avalon), drop=FALSE]

table(missing_count_ava <- sapply(global_Obssumstats_avalon, function(x) sum(is.na(x))))

global_Obssumstats_avalon$GSSp_D1_Ava <- 0

#save(global_Obssumstats_avalon, 
#     file=paste0("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/global_Obssumstats_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/global_Obssumstats_avalon",".RData"))

## PLACERITA POPULATION
##-----------------------------

# global summary stats reftable
load("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/placerita_globalStats_reftable.RData")

global_Obssumstats_placerita <- data2globalStats

global_Obssumstats_placerita <- global_Obssumstats_placerita[, names(global_Obssumstats_placerita) %in% names(global_sumstats4training_placerita), drop=FALSE]

table(missing_count_pla <- sapply(global_Obssumstats_placerita, function(x) sum(is.na(x))))

#save(global_Obssumstats_placerita, 
#     file=paste0("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/global_Obssumstats_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/data/ApisMellifera/globalStats_reftable/global_Obssumstats_placerita",".RData"))

```

## Sampling period inference

### ABC-RF classification for selection: growing trees

#### Classification based on the proportion of strongly selected mutations - POPPrStrongMSel: quasi-Neutral vs strong-Selection
```{r classification neutral selection, echo=TRUE, eval=FALSE, include=TRUE}

## AVALON POPULATION
##-----------------------------
selection_avalon <- ifelse(pooled_reftable_bees_avalon[, "POPPrStrongMSel_Ava"] == 0, "qNeutral", "sSel")
table(selection_avalon)

# Create a reftable with equal number of qNeutral and sSel simulations
qNeutral.sims.idx <- which(selection_avalon == "qNeutral")
qNeutral.GSSs <- global_sumstats4training_avalon[qNeutral.sims.idx, ]
qNeutral.sims <- selection_avalon[qNeutral.sims.idx]

# sample size = # qNeutral simulations
sSel.sims.idx <- sample(x=which(selection_avalon == "sSel"), size=length(qNeutral.sims.idx), replace = F)
sSel.GSSs <- global_sumstats4training_avalon[sSel.sims.idx, ]
sSel.sims <- selection_avalon[sSel.sims.idx]

selection_avalon_subset <- c(qNeutral.sims, sSel.sims)
gss_avalon_subset <- rbind(qNeutral.GSSs, sSel.GSSs)

## rf-classification
class_selection_avalon <- abcrf(formula = selection_avalon_subset~.,
                                data    = data.frame(selection_avalon_subset, gss_avalon_subset[,-c(19,22,25,120)]),
                                lda     = TRUE, 
                                ntree   = 1000,
                                paral   = T,
                                ncores  = 6)

#save(class_selection_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/class_selection_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/class_selection_avalon",".RData"))

(class_selection_avalon)
#Number of simulations: 9670
#Out-of-bag prior error rate: 23.878%
#
#Confusion matrix:
#         qNeutral sSel class.error
#qNeutral     4050  785   0.1623578
#sSel         1524 3311   0.3152017

#TPR = 4050/(4050+1524) = 0.7265877 #sensitivity, recall
#TNR = 3311/(3311+785) = 0.8083496 #specificity, selectivity
#PPV = 4050/(4050+785) = 0.8376422 # precision
#NPV = 3311/(3311+1524) = 0.6847983

#same as:
#table(class_selection_avalon, class_selection_avalon$model.rf$predictions)

# GLOBAL ERROR
sum(as.character(class_selection_avalon$model.rf$predictions)!=selection_avalon_subset)/length(selection_avalon_subset)
class_selection_avalon$model.rf$confusion.matrix
#0.2387797
#         qNeutral sSel class.error
#qNeutral     4050  785   0.1623578
#sSel         1524 3311   0.3152017

## error rate plot
err.abcrf(object   = class_selection_avalon,
          training = data.frame(selection_avalon_subset, gss_avalon_subset[,-c(19,22,25,120)]),
          paral    = T,
         ncores   = 6)

plot(class_selection_avalon, 
     training = data.frame(selection_avalon_subset, gss_avalon_subset[,-c(19,22,25,120)]),
     obs=NULL, 
     n.var=20)

## Classification as a function of theta*PS

# theta * P_S 
#-----------------------------------------------------------
genomeS = 250e+6
prRSel_ava <- pooled_reftable_bees_avalon[, "PrGWSel"] * pooled_reftable_bees_avalon[, "PrMSel"]
  
logthetaPS_ava <- log10(4 * pooled_reftable_bees_avalon[, "Ncs"] * (pooled_reftable_bees_avalon[, "mu"] * prRSel_ava) * genomeS)

obs_pred_class <- data.frame(obs=selection_avalon_subset, 
                             pred=class_selection_avalon$model.rf$predictions, 
                             logthetaPS=logthetaPS_ava[c(qNeutral.sims.idx, sSel.sims.idx)]) 

error <- (obs_pred_class$obs!=obs_pred_class$pred)

tol<-0.2
local_error <- array(NA,nrow(obs_pred_class))
for (i in seq_len(nrow(obs_pred_class))){
  
    distance <- abs(obs_pred_class$logthetaPS-obs_pred_class$logthetaPS[i])
  
  # calculate weigths from epachnikov kernel
  nacc <- ceiling(length(distance) * tol)
  ds   <- sort(distance)[nacc]
  weights <- 1 - (distance/ds)^2
  weights[which(weights<0)]<-0

  # calculated weighthed proportion of error
  local_error[i]<-sum(error*weights)/sum(weights)
}

obs_pred_class["error"] <- local_error

obs_pred_class <- obs_pred_class[order(obs_pred_class$logthetaPS),]

#save(obs_pred_class, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/obs_pred_class_error_ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/obs_pred_class_error_ava",".RData"))

# simple plot
#plot(obs_pred_class$logthetaPS,
#     obs_pred_class$error,
#     xlab=expression(log[10](italic(θ) * italic(P)[S])),
#     ylab="error rate",
#     type="l",lwd=2,col="red")
#abline(v=0)

# manuscript plot
class_theta <- ggplot(obs_pred_class , aes(x=logthetaPS, y=error, colour=logthetaPS))
class_theta_g <- class_theta + 
                 geom_line(size = 1.2) + 
                 scale_colour_gradientn(colours=viridis::plasma(32),name="",
                                      breaks = c(-3,0,3),labels = c(-3,0,3)) +
                 xlab(expression(log[10](italic(θ)*italic(P)[S]))) +
                 ylab("error rate") +
                 geom_vline(xintercept = 0, color = "black") + 
                 geom_segment(x = 0.05, y = 0.43, xend = 4, yend = 0.43, color="black",
                              arrow = arrow(length = unit(0.5, "cm"))) +
                 geom_segment(x = 0.05, y = 0.43, xend = -5, yend = 0.43, color="black",
                              arrow = arrow(length = unit(0.5, "cm"))) +
                 annotate("text", x = 2, y = 0.42, label = "mutation unlimited",color = "black", fontface = 1) +
                 annotate("text", x = -3, y = 0.42, label = "mutation limited",color = "black", fontface = 1) +
                 theme_bw() + 
                 theme(panel.border = element_rect(colour = "black", fill=NA), 
                 panel.grid.major = element_blank(),
                 panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),
                 legend.position = "top", axis.text = element_text(size = 12),
                 axis.title=element_text(size=12))
class_theta_g

## PLACERITA POPULATION
##-----------------------------
selection_placerita <- ifelse(pooled_reftable_bees_placerita[, "POPPrStrongMSel_Pla"] == 0, "qNeutral", "sSel")
table(selection_placerita)

# Create a reftable with equal number of qNeutral and sSel simulations
qNeutral.sims.idx <- which(selection_placerita == "qNeutral")
qNeutral.GSSs <- global_sumstats4training_placerita[qNeutral.sims.idx, ]
qNeutral.sims <- selection_placerita[qNeutral.sims.idx]

# sample size = # qNeutral simulations
sSel.sims.idx <- sample(x=which(selection_placerita == "sSel"), size=length(qNeutral.sims.idx), replace = F)
sSel.GSSs <- global_sumstats4training_placerita[sSel.sims.idx, ]
sSel.sims <- selection_placerita[sSel.sims.idx]

selection_placerita_subset <- c(qNeutral.sims, sSel.sims)
gss_placerita_subset <- rbind(qNeutral.GSSs, sSel.GSSs)

## rf-classification
class_selection_placerita <- abcrf(formula = selection_placerita_subset~.,
                                data    = data.frame(selection_placerita_subset, gss_placerita_subset),
                                lda     = TRUE, 
                                ntree   = 1000,
                                paral   = T,
                                ncores  = 6)

#save(class_selection_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/class_selection_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/class_selection_placerita",".RData"))

(class_selection_placerita)
#Number of simulations: 11516
#Out-of-bag prior error rate: 28.3171%
#
#Confusion matrix:
#         qNeutral sSel class.error
#qNeutral     4706 1052   0.1827023
#sSel         2209 3549   0.3836402

#TPR = 4706/(4706+2209) = 0.6805495 #sensitivity, recall
#TNR = 3549/(3549+1052) = 0.7713541 #specificity, selectivity
#PPV = 4706/(4706+1052) = 0.8172977 # precision
#NPV = 3549/(3549+2209) = 0.6163598

#same as:
#table(class_selection_placerita, class_selection_placerita$model.rf$predictions)

# GLOBAL ERROR
sum(as.character(class_selection_placerita$model.rf$predictions)!=selection_placerita_subset)/length(selection_placerita_subset)
class_selection_placerita$model.rf$confusion.matrix
#0.2831712
#         qNeutral sSel class.error
#qNeutral     4706 1052   0.1827023
#sSel         2209 3549   0.3836402

## error rate plot
err.abcrf(object   = class_selection_placerita,
          training = data.frame(selection_placerita_subset, gss_placerita_subset),
          paral    = T,
         ncores   = 6)

plot(class_selection_placerita, 
     training = data.frame(selection_placerita_subset, gss_placerita_subset),
     obs=NULL, 
     n.var=20)

## Classification as a function of theta*PS

# theta * P_S 
#-----------------------------------------------------------
genomeS = 250e+6
prRSel_pla <- pooled_reftable_bees_placerita[, "PrGWSel"] * pooled_reftable_bees_placerita[, "PrMSel"]
  
logthetaPS_pla <- log10(4 * pooled_reftable_bees_placerita[, "Ncs"] * (pooled_reftable_bees_placerita[, "mu"] * prRSel_pla) * genomeS)

obs_pred_class <- data.frame(obs=selection_placerita_subset, 
                             pred=class_selection_placerita$model.rf$predictions, 
                             logthetaPS=logthetaPS_pla[c(qNeutral.sims.idx, sSel.sims.idx)]) 

error <- (obs_pred_class$obs!=obs_pred_class$pred)

tol<-0.2
local_error <- array(NA,nrow(obs_pred_class))
for (i in seq_len(nrow(obs_pred_class))){
  
    distance <- abs(obs_pred_class$logthetaPS-obs_pred_class$logthetaPS[i])
  
  # calculate weigths from epachnikov kernel
  nacc <- ceiling(length(distance) * tol)
  ds   <- sort(distance)[nacc]
  weights <- 1 - (distance/ds)^2
  weights[which(weights<0)]<-0

  # calculated weighthed proportion of error
  local_error[i]<-sum(error*weights)/sum(weights)
}

obs_pred_class["error"] <- local_error

obs_pred_class <- obs_pred_class[order(obs_pred_class$logthetaPS),]

#save(obs_pred_class, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/obs_pred_class_error_pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/obs_pred_class_error_pla",".RData"))

# simple plot
#plot(obs_pred_class$logthetaPS,
#     obs_pred_class$error,
#     xlab=expression(log[10](italic(θ) * italic(P)[S])),
#     ylab="error rate",
#     type="l",lwd=2,col="red")
#abline(v=0)

# manuscript plot
class_theta <- ggplot(obs_pred_class , aes(x=logthetaPS, y=error, colour=logthetaPS))
class_theta_g <- class_theta + 
                 geom_line(size = 1.2) + 
                 scale_colour_gradientn(colours=viridis::plasma(32),name="",
                                      breaks = c(-3,0,3),labels = c(-3,0,3)) +
                 xlab(expression(log[10](italic(θ)*italic(P)[S]))) +
                 ylab("error rate") +
                 geom_vline(xintercept = 0, color = "black") + 
                 geom_segment(x = 0.05, y = 0.5, xend = 5, yend = 0.5, color="black",
                              arrow = arrow(length = unit(0.5, "cm"))) +
                 geom_segment(x = 0.05, y = 0.5, xend = -5, yend = 0.5, color="black",
                              arrow = arrow(length = unit(0.5, "cm"))) +
                 annotate("text", x = 2.5, y = 0.49, label = "mutation unlimited",color = "black", fontface = 1) +
                 annotate("text", x = -2.5, y = 0.49, label = "mutation limited",color = "black", fontface = 1) +
                 theme_bw() + 
                 theme(panel.border = element_rect(colour = "black", fill=NA), 
                 panel.grid.major = element_blank(),
                 panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"),
                 legend.position = "top", axis.text = element_text(size = 12),
                 axis.title=element_text(size=12))
class_theta_g
```

### ABC-RF regression for selection: growing trees

#### Average genetic load
```{r regression genetic load, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON POPULATION
###-----------------------------------------------------------

averageGenLoad_avalon <- pooled_reftable_bees_avalon[, "averageGenLoad_Ava"]
hist(averageGenLoad_avalon, freq = TRUE, xlab = expression(italic(L)), main = "", col = "#bdbdbd")

## logit transformation I:
# removing "quasi-neutral" simulations
load_zero_avalon <- which(averageGenLoad_avalon == 0)
averageGenLoad_avalon_2 <- averageGenLoad_avalon[-load_zero_avalon]
global_sumstats4training_avalon_averageGenLoad <- global_sumstats4training_avalon[-load_zero_avalon,]

logitaverageGenload_avalon <- log(averageGenLoad_avalon_2/(1-averageGenLoad_avalon_2))
hist(logitaverageGenload_avalon, freq = TRUE, xlab = expression(logit(italic(L))), main = "", col = "#bdbdbd")

## rf-regression
reg_averageGenLoad_avalon_2 <- regAbcrf(formula = logitaverageGenload_avalon~.,
                                        data    = data.frame(logitaverageGenload_avalon, 
                                                             global_sumstats4training_avalon_averageGenLoad),
                                        ntree   = 1000,
                                        paral   = T,
                                        ncores  = 8)

#save(reg_averageGenLoad_avalon_2, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_averageGenLoad_avalon_2",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_averageGenLoad_avalon_2",".RData"))

## variable Importance plot
plot(x = reg_averageGenLoad_avalon_2, n.var = 20)

## prediction error
reg_averageGenLoad_avalon_2$model.rf$prediction.error
# 10.36159
inv.logit(reg_averageGenLoad_avalon_2$model.rf$prediction.error)
#  0.9999684

## error rate plot
#err.regAbcrf(object   = reg_averageGenLoad_avalon_2,
#             training = data.frame(logitaverageGenload_avalon, global_sumstats4training_avalon_averageGenLoad),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
# basic plot for diagnostic
plot(x    = logitaverageGenload_avalon,
     y    = reg_averageGenLoad_avalon_2$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-22,6),
     ylim = c(-22,6),
     main = expression(logit(italic(L))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.lgtgl.ava <- data.frame(x = logitaverageGenload_avalon,
                            y = reg_averageGenLoad_avalon_2$model.rf$predictions)
#save(oob.lgtgl.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtgl.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtgl.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.lgtgl.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", logit(italic(L)))),
       ylab = expression(paste(logit(italic(hat(L))), " ","(OOB prediction)")),
       xlim = c(-22,6),
       ylim = c(-22,6),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA POPULATION
###-----------------------------------------------------------

averageGenLoad_placerita <- pooled_reftable_bees_placerita[, "averageGenLoad_Pla"]
hist(averageGenLoad_placerita, freq = TRUE, xlab = expression(italic(L)), main = "", col = "#bdbdbd")

## logit transformation I:
# removing "quasi-neutral" simulations
load_zero_placerita <- which(averageGenLoad_placerita <= 0)
averageGenLoad_placerita_2 <- averageGenLoad_placerita[-load_zero_placerita]
global_sumstats4training_placerita_averageGenLoad <- global_sumstats4training_placerita[-load_zero_placerita,]

logitaverageGenload_placerita <- log(averageGenLoad_placerita_2/(1-averageGenLoad_placerita_2))
hist(logitaverageGenload_placerita, freq = TRUE, xlab = expression(logit(italic(L))), main = "", col = "#bdbdbd")

## rf-regression
reg_averageGenLoad_placerita_2 <- regAbcrf(formula = logitaverageGenload_placerita~.,
                                        data    = data.frame(logitaverageGenload_placerita, 
                                                             global_sumstats4training_placerita_averageGenLoad),
                                        ntree   = 1000,
                                        paral   = T,
                                        ncores  = 8)

#save(reg_averageGenLoad_placerita_2, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_averageGenLoad_placerita_2",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_averageGenLoad_placerita_2",".RData"))

## variable Importance plot
plot(x = reg_averageGenLoad_placerita_2, n.var = 20)

## prediction error
reg_averageGenLoad_placerita_2$model.rf$prediction.error
# 14.05361
inv.logit(reg_averageGenLoad_placerita_2$model.rf$prediction.error)
#  0.9999992

## error rate plot
#err.regAbcrf(object   = reg_averageGenLoad_placerita_2,
#             training = data.frame(logitaverageGenload_placerita, global_sumstats4training_placerita_averageGenLoad),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
# basic plot for diagnostic
plot(x    = logitaverageGenload_placerita,
     y    = reg_averageGenLoad_placerita_2$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-22,6),
     ylim = c(-22,6),
     main = expression(logit(italic(L))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.lgtgl.pla <- data.frame(x = logitaverageGenload_placerita,
                            y = reg_averageGenLoad_placerita_2$model.rf$predictions)
#save(oob.lgtgl.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtgl.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtgl.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.lgtgl.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", logit(italic(L)))),
       ylab = expression(paste(logit(italic(hat(L))), " ","(OOB prediction)")),
       xlim = c(-22,6),
       ylim = c(-22,6),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Proportion of strongly selected mutations - POPPrStrongMSel
```{r regression strongly selected, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON POPULATION
###-----------------------------------------------------------
prPOPStrongMSel_avalon <- pooled_reftable_bees_avalon[, "POPPrStrongMSel_Ava"]
hist(prPOPStrongMSel_avalon, freq = TRUE, xlab = expression(italic(P)), main = "", col = "#bdbdbd")

## removing "quasi-neutral" simulations
neutralsims_avalon <- which(prPOPStrongMSel_avalon == 0)
prPOPStrongMSel_avalon_2 <- prPOPStrongMSel_avalon[-neutralsims_avalon]
global_sumstats4training_avalon_popstrongmsel <- global_sumstats4training_avalon[-neutralsims_avalon,]

hist(prPOPStrongMSel_avalon_2, freq = TRUE, xlab = expression(italic(P)), main = "", col = "#bdbdbd")

# PrPOPStrongMSel_2 - without neutral/quasi-neutral simulations
logitpopstrongmsel_avalon <- log(prPOPStrongMSel_avalon_2/(1-prPOPStrongMSel_avalon_2))
hist(logitpopstrongmsel_avalon, freq = TRUE, xlab = expression(logit(italic(P))), main = "", col = "#bdbdbd")

## rf-regression
reg_logitpopstrongmsel_avalon <- regAbcrf(formula = logitpopstrongmsel_avalon~.,
                                            data    = data.frame(logitpopstrongmsel_avalon, global_sumstats4training_avalon_popstrongmsel),
                                            ntree   = 1000,
                                            paral   = T,
                                            ncores  = 8)

#save(reg_logitpopstrongmsel_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logitpopstrongmsel_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logitpopstrongmsel_avalon",".RData"))

## variable Importance plot
plot(x = reg_logitpopstrongmsel_avalon, n.var = 20)

#head(sort(reg_logpopstrongmsel_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logitpopstrongmsel_avalon$model.rf$prediction.error
# 1.53131

## error rate plot
#err.regAbcrf(object   = reg_logitpopstrongmsel_avalon,
#             training = data.frame(logitpopstrongmsel, global_sumstats4training_avalon_popstrongmsel),
#             paral    = T,
#            ncores   = 8)

## oob predictions vs true values
# diagnostic plot
plot(x    = logitpopstrongmsel_avalon,
     y    = reg_logitpopstrongmsel_avalon$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-17,2),
     ylim = c(-17,2),
     main = expression(logit(italic(P))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.lgtps.ava <- data.frame(x = logitpopstrongmsel_avalon,
                            y = reg_logitpopstrongmsel_avalon$model.rf$predictions)

#save(oob.lgtps.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtps.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtps.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.lgtps.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", logit(italic(P)))),
       ylab = expression(paste(logit(italic(hat(P))), " ","(OOB prediction)")),
       xlim = c(-17,2),
       ylim = c(-17,2),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA POPULATION
###-----------------------------------------------------------
prPOPStrongMSel_placerita <- pooled_reftable_bees_placerita[, "POPPrStrongMSel_Pla"]
hist(prPOPStrongMSel_placerita, freq = TRUE, xlab = expression(italic(P)), main = "", col = "#bdbdbd")

## removing "quasi-neutral" simulations
neutralsims_placerita <- which(prPOPStrongMSel_placerita == 0)
prPOPStrongMSel_placerita_2 <- prPOPStrongMSel_placerita[-neutralsims_placerita]
global_sumstats4training_placerita_popstrongmsel <- global_sumstats4training_placerita[-neutralsims_placerita,]

hist(prPOPStrongMSel_placerita_2, freq = TRUE, xlab = expression(italic(P)), main = "", col = "#bdbdbd")

# PrPOPStrongMSel_2 - without neutral/quasi-neutral simulations
logitpopstrongmsel_placerita <- log(prPOPStrongMSel_placerita_2/(1-prPOPStrongMSel_placerita_2))
hist(logitpopstrongmsel_placerita, freq = TRUE, xlab = expression(logit(italic(P))), main = "", col = "#bdbdbd")

## rf-regression
reg_logitpopstrongmsel_placerita <- regAbcrf(formula = logitpopstrongmsel_placerita~.,
                                            data    = data.frame(logitpopstrongmsel_placerita, global_sumstats4training_placerita_popstrongmsel),
                                            ntree   = 1000,
                                            paral   = T,
                                            ncores  = 8)

#save(reg_logitpopstrongmsel_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logitpopstrongmsel_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logitpopstrongmsel_placerita",".RData"))

## variable Importance plot
plot(x = reg_logitpopstrongmsel_placerita, n.var = 20)

#head(sort(reg_logpopstrongmsel_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logitpopstrongmsel_placerita$model.rf$prediction.error
# 1.728943

## error rate plot
#err.regAbcrf(object   = reg_logitpopstrongmsel_placerita,
#             training = data.frame(logitpopstrongmsel_placerita, global_sumstats4training_placerita_popstrongmsel),
#             paral    = T,
#            ncores   = 8)

## oob predictions vs true values
# diagnostic plot
plot(x    = logitpopstrongmsel_placerita,
     y    = reg_logitpopstrongmsel_placerita$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-17,2),
     ylim = c(-17,2),
     main = expression(logit(italic(P))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.lgtps.pla <- data.frame(x = logitpopstrongmsel_placerita,
                            y = reg_logitpopstrongmsel_placerita$model.rf$predictions)

#save(oob.lgtps.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtps.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.lgtps.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.lgtps.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", logit(italic(P)))),
       ylab = expression(paste(logit(italic(hat(P))), " ","(OOB prediction)")),
       xlim = c(-17,2),
       ylim = c(-17,2),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Theta selected mutations
```{r regression thetaS, echo=TRUE, eval=FALSE, include=TRUE}
genomeS = 250e+6

### AVALON theta * P_S 
###-----------------------------------------------------------
prRSel_ava <- pooled_reftable_bees_avalon[, "PrGWSel"] * pooled_reftable_bees_avalon[, "PrMSel"]
logthetaPS_ava <- log10(4 * pooled_reftable_bees_avalon[, "Ncs"] * (pooled_reftable_bees_avalon[, "mu"] * prRSel_ava) * genomeS)

hist(logthetaPS_ava, freq = TRUE, xlab = expression(log[10](italic(θ) * italic(P)[S])), main = "", col = "#bdbdbd")

## rf-regression
reg_logthetaPS_avalon <- regAbcrf(formula = logthetaPS_ava~.,
                                 data    = data.frame(logthetaPS_ava, global_sumstats4training_avalon),
                                 ntree   = 1000,
                                 paral   = T,
                                 ncores  = 8)

#save(reg_logthetaPS_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logthetaPS_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logthetaPS_avalon",".RData"))

## variable Importance plot
plot(x = reg_logthetaPS_avalon, n.var = 20)

#head(sort(reg_logthetaPS_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logthetaPS_avalon$model.rf$prediction.error
# 1.579821

## error rate plot
#err.regAbcrf(object   = reg_logthetaPS_avalon,
#             training = data.frame(logthetaPS_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logthetaPS_ava,
     y    = reg_logthetaPS_avalon$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-7,5),
     ylim = c(-7,5),
     main = expression(log[10](italic(theta*P[S]))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logthetaPS.ava <- data.frame(x = logthetaPS_ava,
                                 y = reg_logthetaPS_avalon$model.rf$predictions)

#save(oob.logthetaPS.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logthetaPS.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logthetaPS.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logthetaPS.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(θ) * italic(P)[S]))),
       ylab = expression(paste(log[10](italic(hat(θ))*italic(P)[S]), " ","(OOB prediction)")),
       xlim = c(-7,5),
       ylim = c(-7,5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA theta * P_S 
###-----------------------------------------------------------
prRSel_pla <- pooled_reftable_bees_placerita[, "PrGWSel"] * pooled_reftable_bees_placerita[, "PrMSel"]
logthetaPS_pla <- log10(4 * pooled_reftable_bees_placerita[, "Ncs"] * (pooled_reftable_bees_placerita[, "mu"] * prRSel_pla) * genomeS)

hist(logthetaPS_pla, freq = TRUE, xlab = expression(log[10](italic(θ) * italic(P)[S])), main = "", col = "#bdbdbd")

## rf-regression
reg_logthetaPS_placerita <- regAbcrf(formula = logthetaPS_pla~.,
                                 data    = data.frame(logthetaPS_pla, global_sumstats4training_placerita),
                                 ntree   = 1000,
                                 paral   = T,
                                 ncores  = 8)

save(reg_logthetaPS_placerita, 
     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logthetaPS_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logthetaPS_placerita",".RData"))

## variable Importance plot
plot(x = reg_logthetaPS_placerita, n.var = 20)

#head(sort(reg_logthetaPS_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logthetaPS_placerita$model.rf$prediction.error
# 1.735243

## error rate plot
#err.regAbcrf(object   = reg_logthetaPS_placerita,
#             training = data.frame(logthetaPS_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logthetaPS_pla,
     y    = reg_logthetaPS_placerita$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-7,5),
     ylim = c(-7,5),
     main = expression(log[10](italic(theta*P[S]))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logthetaPS.pla <- data.frame(x = logthetaPS_pla,
                                 y = reg_logthetaPS_placerita$model.rf$predictions)

#save(oob.logthetaPS.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logthetaPS.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logthetaPS.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logthetaPS.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(θ) * italic(P)[S]))),
       ylab = expression(paste(log[10](italic(hat(θ))*italic(P)[S]), " ","(OOB prediction)")),
       xlim = c(-7,5),
       ylim = c(-7,5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Ns
```{r regression Ns, echo=TRUE, eval=FALSE, include=TRUE}

## AVALON POPULATION
##-------------------------------------

logNs_ava <- log10(pooled_reftable_bees_avalon[, "meanNe2_Ava"] * pooled_reftable_bees_avalon[, "gammaMean"])

hist(logNs_ava, freq = TRUE, xlab = expression(log[10](italic(N)[e] * italic(s))), main = "", col = "#bdbdbd")

# abf-rf regression
reg_logNs_avalon <- regAbcrf(formula = logNs_ava~.,
                      data    = data.frame(logNs_ava, global_sumstats4training_avalon),
                      ntree   = 1000,
                      paral   = T,
                      ncores  = 8)

#save(reg_logNs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logNs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logNs_avalon",".RData"))

# variable Importance plot
plot(x = reg_logNs_avalon, n.var = 20, main=expression(log[10](italic(N)[e] * italic(s))))

#head(sort(reg_logNs_avalon$model.rf$variable.importance, decreasing = T), n=20)

# prediction error
reg_logNs_avalon$model.rf$prediction.error
# 0.6980215

# error rate plot
#err.regAbcrf(object   = reg_logNs_avalon,
#             training = data.frame(logNs_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
## diagnostic plot
plot(x    = logNs_ava,
     y    = reg_logNs_avalon$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-4,4),
     ylim = c(-4,4),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logNs.ava <- data.frame(x = logNs_ava,
                            y = reg_logNs_avalon$model.rf$predictions)

#save(oob.logNs.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logNs.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logNs.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logNs.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e] * italic(s)))),
       ylab = expression(paste(log[10](italic(hat(N))[e] * italic(s)), " ","(OOB prediction)")),
       xlim = c(-4,4),
       ylim = c(-4,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

## PLACERITA POPULATION
##-------------------------------------

logNs_pla <- log10(pooled_reftable_bees_placerita[, "meanNe2_Pla"] * pooled_reftable_bees_placerita[, "gammaMean"])

hist(logNs_pla, freq = TRUE, xlab = expression(log[10](italic(N)[e] * italic(s))), main = "", col = "#bdbdbd")

# abf-rf regression
reg_logNs_placerita <- regAbcrf(formula = logNs_pla~.,
                      data    = data.frame(logNs_pla, global_sumstats4training_placerita),
                      ntree   = 1000,
                      paral   = T,
                      ncores  = 8)

#save(reg_logNs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logNs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logNs_placerita",".RData"))

# variable Importance plot
plot(x = reg_logNs_placerita, n.var = 20, main=expression(log[10](italic(N)[e] * italic(s))))

#head(sort(reg_logNs_placerita$model.rf$variable.importance, decreasing = T), n=20)

# prediction error
reg_logNs_placerita$model.rf$prediction.error
# 0.6888039

# error rate plot
#err.regAbcrf(object   = reg_logNs_placerita,
#             training = data.frame(logNs_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
## diagnostic plot
plot(x    = logNs_pla,
     y    = reg_logNs_placerita$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-4,4),
     ylim = c(-4,4),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logNs.pla <- data.frame(x = logNs_pla,
                            y = reg_logNs_placerita$model.rf$predictions)

#save(oob.logNs.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logNs.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logNs.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logNs.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e] * italic(s)))),
       ylab = expression(paste(log[10](italic(hat(N))[e] * italic(s)), " ","(OOB prediction)")),
       xlim = c(-4,4),
       ylim = c(-4,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

### ABC-RF regression for demography: growing trees

#### Harmonic mean of the effective population sizes of period 2
```{r regression meanNe2, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------

logmeanNe2_ava <- log10(pooled_reftable_bees_avalon[, "meanNe2_Ava"])
hist(logmeanNe2_ava, freq = TRUE, xlab = expression(log[10](italic(N)[e])) , main = "", col = "#bdbdbd")

## rf-regression
reg_logmeanNe2_avalon <- regAbcrf(formula = logmeanNe2_ava~.,
                                  data    = data.frame(logmeanNe2_ava, global_sumstats4training_avalon),
                                  ntree   = 1000,
                                  paral   = T,
                                  ncores  = 8)

#save(reg_logmeanNe2_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2_avalon",".RData"))

## Variable Importance plot
plot(x = reg_logmeanNe2_avalon, n.var = 20)

#head(sort(reg_logmeanNe2_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logmeanNe2_avalon$model.rf$prediction.error
# 0.05146832

## error rate plot
#err.regAbcrf(object   = reg_logmeanNe2_ava,
#             training = data.frame(logmeanNe2_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
# diagnostic plot
plot(x    = logmeanNe2_ava,
     y    = reg_logmeanNe2_avalon$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(0,4),
     ylim = c(0,4),
     main = expression(log[10](italic(N[e]))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logmeanNe2.ava <- data.frame(x = logmeanNe2_ava,
                                 y = reg_logmeanNe2_avalon$model.rf$predictions)

#save(oob.logmeanNe2.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logmeanNe2.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]), " ","(OOB prediction)")),
       xlim = c(-0,4),
       ylim = c(-0,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

## Comparison with the NE calculation based on the temporal FST
globalFSTNe <- function(x, tau){
  fst  <- x
  ne <- (tau*(1-fst))/(4*fst)
  return(ne)
}

logfstne2.ava <- log10(globalFSTNe(x=global_sumstats4training_avalon$GSS_WCst, tau=104))

estimated.fstNe2.ava <- data.frame(x = logmeanNe2_ava,
                                   y = logfstne2.ava)

#save(estimated.fstNe2.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/estimated.fstNe2.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/estimated.fstNe2.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(estimated.fstNe2.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]), " ","(from", " ", italic(hat(F))[ST], ")")),
       xlim = c(-0.5,4),
       ylim = c(-0.5,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA
###-----------------------------------------------------------

logmeanNe2_pla <- log10(pooled_reftable_bees_placerita[, "meanNe2_Pla"])
hist(logmeanNe2_pla, freq = TRUE, xlab = expression(log[10](italic(N)[e])) , main = "", col = "#bdbdbd")

## rf-regression
reg_logmeanNe2_placerita <- regAbcrf(formula = logmeanNe2_pla~.,
                                  data    = data.frame(logmeanNe2_pla, global_sumstats4training_placerita),
                                  ntree   = 1000,
                                  paral   = T,
                                  ncores  = 8)

#save(reg_logmeanNe2_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2_placerita",".RData"))

## Variable Importance plot
plot(x = reg_logmeanNe2_placerita, n.var = 20)

#head(sort(reg_logmeanNe2_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logmeanNe2_placerita$model.rf$prediction.error
# 0.04208454

## error rate plot
#err.regAbcrf(object   = reg_logmeanNe2_pla,
#             training = data.frame(logmeanNe2_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 8)

## oob predictions vs true values
# diagnostic plot
plot(x    = logmeanNe2_pla,
     y    = reg_logmeanNe2_placerita$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(0,4),
     ylim = c(0,4),
     main = expression(log[10](italic(N[e]))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logmeanNe2.pla <- data.frame(x = logmeanNe2_pla,
                                 y = reg_logmeanNe2_placerita$model.rf$predictions)

#save(oob.logmeanNe2.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logmeanNe2.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]), " ","(OOB prediction)")),
       xlim = c(-0,4),
       ylim = c(-0,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

## Comparison with the NE calculation based on the temporal FST
globalFSTNe <- function(x, tau){
  fst  <- x
  ne <- (tau*(1-fst))/(4*fst)
  return(ne)
}

logfstne2.pla <- log10(globalFSTNe(x=global_sumstats4training_placerita$GSS_WCst, tau=15))

estimated.fstNe2.pla <- data.frame(x = logmeanNe2_pla,
                                   y = logfstne2.pla)

#save(estimated.fstNe2.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/estimated.fstNe2.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/estimated.fstNe2.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(estimated.fstNe2.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]), " ","(from", " ", italic(hat(F))[ST], ")")),
       xlim = c(-0.5,4),
       ylim = c(-0.5,4),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Population size of period 2 - census size Ncs
```{r regression Ncs, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------

logncs_ava <- log10(pooled_reftable_bees_avalon[, "Ncs"])
hist(logncs_ava, freq = TRUE, xlab = expression(log[10](italic(N)[cs])), main = "", col = "#bdbdbd")

## rf-regression
reg_logncs_avalon <- regAbcrf(formula = logncs_ava~.,
                                 data = data.frame(logncs_ava, global_sumstats4training_avalon),
                                ntree = 1000,
                                paral = T,
                               ncores = 8)

#save(reg_logncs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logncs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logncs_avalon",".RData"))

## Variable Importance plot
plot(x = reg_logncs_avalon, n.var = 20)

#head(sort(reg_logn_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logncs_avalon$model.rf$prediction.error
# 0.1083586

## error rate plot
#err.regAbcrf(object   = reg_logncs_avalon,
#             training = data.frame(logncs_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logncs_ava,
     y    = reg_logncs_avalon$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(0,4),
     ylim = c(0,4),
     main = expression(log[10](italic(N))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logncs.ava <- data.frame(x = logncs_ava,
                             y = reg_logncs_avalon$model.rf$predictions)

#save(oob.logncs.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logncs.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logncs.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logncs.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[cs]))),
       ylab = expression(paste(log[10](italic(hat(N))[cs]), " ","(OOB prediction)")),
       xlim = c(-0.5,3.5),
       ylim = c(-0.5,3.5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA
###-----------------------------------------------------------

logncs_pla <- log10(pooled_reftable_bees_placerita[, "Ncs"])
hist(logncs_pla, freq = TRUE, xlab = expression(log[10](italic(N)[cs])), main = "", col = "#bdbdbd")

## rf-regression
reg_logncs_placerita <- regAbcrf(formula = logncs_pla~.,
                                 data = data.frame(logncs_pla, global_sumstats4training_placerita),
                                ntree = 1000,
                                paral = T,
                               ncores = 8)

#save(reg_logncs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logncs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logncs_placerita",".RData"))

## Variable Importance plot
plot(x = reg_logncs_placerita, n.var = 20)

#head(sort(reg_logn_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logncs_placerita$model.rf$prediction.error
# 0.0859845

## error rate plot
#err.regAbcrf(object   = reg_logncs_placerita,
#             training = data.frame(logncs_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logncs_pla,
     y    = reg_logncs_placerita$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(0,4),
     ylim = c(0,4),
     main = expression(log[10](italic(N))),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logncs.pla <- data.frame(x = logncs_pla,
                             y = reg_logncs_placerita$model.rf$predictions)

#save(oob.logncs.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logncs.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logncs.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logncs.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[cs]))),
       ylab = expression(paste(log[10](italic(hat(N))[cs]), " ","(OOB prediction)")),
       xlim = c(-0.5,3.5),
       ylim = c(-0.5,3.5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

Ratio Mean effective size / population size of period 2 - MeanNe2/Ncs
```{r regression MeanNe2Ncs, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
logmeanNe2ncs_ava <- log10(pooled_reftable_bees_avalon[, "meanNe2_Ava"]/pooled_reftable_bees_avalon[, "Ncs"])

hist(logmeanNe2ncs_ava, freq = TRUE, xlab = expression(log[10](italic(N)[e]/italic(N)[cs])), main = "", col = "#bdbdbd")

## rf-regression
reg_logmeanNe2ncs_avalon <- regAbcrf(formula = logmeanNe2ncs_ava~.,
                                 data = data.frame(logmeanNe2ncs_ava, global_sumstats4training_avalon),
                                ntree = 1000,
                                paral = T,
                               ncores = 28)

#save(reg_logmeanNe2ncs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2ncs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2ncs_avalon",".RData"))

## Variable Importance plot
plot(x = reg_logmeanNe2ncs_avalon, n.var = 20, main=expression(log[10](italic(N)[e]/italic(N)[cs])))

#head(sort(reg_logmeanNe2ncs_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logmeanNe2ncs_avalon$model.rf$prediction.error
# 0.05099813

# error rate plot
#err.regAbcrf(object   = reg_logmeanNe2ncs_avalon,
#             training = data.frame(logmeanNe2ncs_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logmeanNe2ncs_ava,
     y    = reg_logmeanNe2ncs_avalon$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-5,1),
     ylim = c(-5,1),
     main = expression(log[10](italic(N)[e]/italic(N)[cs])),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logmeanNe2ncs.ava <- data.frame(x = logmeanNe2ncs_ava,
                                    y = reg_logmeanNe2ncs_avalon$model.rf$predictions)

#save(oob.logmeanNe2ncs.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2ncs.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2ncs.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logmeanNe2ncs.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]/italic(N)[cs]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]/italic(N)[cs]), " ","(OOB prediction)")),
       xlim = c(-3.5,0.5),
       ylim = c(-3.5,0.5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

### PLACERITA
###-----------------------------------------------------------
logmeanNe2ncs_pla <- log10(pooled_reftable_bees_placerita[, "meanNe2_Pla"]/pooled_reftable_bees_placerita[, "Ncs"])

hist(logmeanNe2ncs_pla, freq = TRUE, xlab = expression(log[10](italic(N)[e]/italic(N)[cs])), main = "", col = "#bdbdbd")

## rf-regression
reg_logmeanNe2ncs_placerita <- regAbcrf(formula = logmeanNe2ncs_pla~.,
                                 data = data.frame(logmeanNe2ncs_pla, global_sumstats4training_placerita),
                                ntree = 1000,
                                paral = T,
                               ncores = 28)

#save(reg_logmeanNe2ncs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2ncs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logmeanNe2ncs_placerita",".RData"))

## Variable Importance plot
plot(x = reg_logmeanNe2ncs_placerita, n.var = 20, main=expression(log[10](italic(N)[e]/italic(N)[cs])))

#head(sort(reg_logmeanNe2ncs_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logmeanNe2ncs_placerita$model.rf$prediction.error
# 0.03123464

# error rate plot
#err.regAbcrf(object   = reg_logmeanNe2ncs_placerita,
#             training = data.frame(logmeanNe2ncs_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logmeanNe2ncs_pla,
     y    = reg_logmeanNe2ncs_placerita$model.rf$predictions,
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-5,1),
     ylim = c(-5,1),
     main = expression(log[10](italic(N)[e]/italic(N)[cs])),
     cex.axis = 1.2,
     cex.lab  = 1.2)
abline(a=0, b=1, col = "green")

# manuscript plot
oob.logmeanNe2ncs.pla <- data.frame(x = logmeanNe2ncs_pla,
                                    y = reg_logmeanNe2ncs_placerita$model.rf$predictions)

#save(oob.logmeanNe2ncs.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2ncs.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logmeanNe2ncs.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logmeanNe2ncs.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(N)[e]/italic(N)[cs]))),
       ylab = expression(paste(log[10](italic(hat(N))[e]/italic(N)[cs]), " ","(OOB prediction)")),
       xlim = c(-3.5,0.5),
       ylim = c(-3.5,0.5),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Theta of perid 2
```{r regression theta 2, echo=TRUE, eval=FALSE, include=TRUE}
genomeS =  250e+6

## AVALON
##--------------------------------
logtheta2_ava <- log10(4 * pooled_reftable_bees_avalon[, "meanNe2_Ava"] * (pooled_reftable_bees_avalon[, "mu"]) * genomeS)

hist(logtheta2_ava, freq = TRUE, xlab = expression(log[10](italic(θ))), main = "", col = "#bdbdbd")

reg_logtheta2_avalon <- regAbcrf(formula = logtheta2_ava~.,
                                 data    = data.frame(logtheta2_ava, global_sumstats4training_avalon),
                                 ntree   = 1000,
                                 paral   = T,
                                 ncores  = 8)

#save(reg_logtheta2_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logtheta2_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logtheta2_avalon",".RData"))

## variable Importance plot
plot(x = reg_logtheta2_avalon, n.var = 20, main=expression(log[10](italic(θ))))

#head(sort(reg_logtheta2_avalon$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logtheta2_avalon$model.rf$prediction.error
# 0.03717215

## error rate plot
#err.regAbcrf(object   = reg_logtheta2_avalon,
#             training = data.frame(logtheta2_ava, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logtheta2_ava,
     y    = reg_logtheta2_avalon$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-2,6),
     ylim = c(-2,6),
     main = expression(log[10](italic(theta))),
     cex.axis = 1.2,
     cex.lab  = 1.5)
abline(a=0, b=1, col = "green")

# Manuscript plot
oob.logtheta2.ava <- data.frame(x = logtheta2_ava,
                                y = reg_logtheta2_avalon$model.rf$predictions)

#save(oob.logtheta2.ava, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logtheta2.ava",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logtheta2.ava",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logtheta2.ava, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(θ)))),
       ylab = expression(paste(log[10](italic(hat(θ))), " ","(OOB prediction)")),
       xlim = c(-1.5,6),
       ylim = c(-1.5,6),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)

## PLACERITA
##--------------------------------
logtheta2_pla <- log10(4 * pooled_reftable_bees_placerita[, "meanNe2_Pla"] * (pooled_reftable_bees_placerita[, "mu"]) * genomeS)

hist(logtheta2_pla, freq = TRUE, xlab = expression(log[10](italic(θ))), main = "", col = "#bdbdbd")

reg_logtheta2_placerita <- regAbcrf(formula = logtheta2_pla~.,
                                 data    = data.frame(logtheta2_pla, global_sumstats4training_placerita),
                                 ntree   = 1000,
                                 paral   = T,
                                 ncores  = 8)

#save(reg_logtheta2_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logtheta2_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/reg_logtheta2_placerita",".RData"))

## variable Importance plot
plot(x = reg_logtheta2_placerita, n.var = 20, main=expression(log[10](italic(θ))))

#head(sort(reg_logtheta2_placerita$model.rf$variable.importance, decreasing = T), n=20)

## prediction error
reg_logtheta2_placerita$model.rf$prediction.error
# 0.02539776

## error rate plot
#err.regAbcrf(object   = reg_logtheta2_placerita,
#             training = data.frame(logtheta2_pla, global_sumstats4training_placerita),
#             paral    = T,
#             ncores   = 28)

## oob predictions vs true values
# diagnostic plot
plot(x    = logtheta2_pla,
     y    = reg_logtheta2_placerita$model.rf$predictions, 
     xlab = "True value",
     ylab = "OOB predictions",
     xlim = c(-2,6),
     ylim = c(-2,6),
     main = expression(log[10](italic(theta))),
     cex.axis = 1.2,
     cex.lab  = 1.5)
abline(a=0, b=1, col = "green")

# Manuscript plot
oob.logtheta2.pla <- data.frame(x = logtheta2_pla,
                                y = reg_logtheta2_placerita$model.rf$predictions)

#save(oob.logtheta2.pla, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logtheta2.pla",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/oob.logtheta2.pla",".RData"))

par(mar=c(5,5,4,1)+.1)
hist2d(oob.logtheta2.pla, nbins=100, 
       col=viridis::viridis(32), 
       FUN=function(x) log(length(x)),
       xlab = expression(paste("true", " ", log[10](italic(θ)))),
       ylab = expression(paste(log[10](italic(hat(θ))), " ","(OOB prediction)")),
       xlim = c(-1.5,6),
       ylim = c(-1.5,6),
       cex.axis = 1.2,
       cex.lab  = 1.2)
abline(a=0, b=1, col = "black", lty = 3)
```

#### Per site mutation rate mu
```{r regression site mutation rate, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
#
#logmu_avalon <- log10(pooled_reftable_bees_avalon[, "mu"])
#
#hist(logmu_avalon, freq = TRUE, xlab = expression(log[10](italic(mu))), main = "", col = "#bdbdbd")
#
## rf-regression
#reg_logmu_avalon <- regAbcrf(formula = logmu_avalon~.,
#                                 data = data.frame(logmu_avalon, global_sumstats4training_avalon),
#                                ntree = 1000,
#                                paral = T,
#                               ncores = 8)
#
#save(reg_logmu_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/reg_logmu_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/reg_logmu_avalon",".RData"))
#
## variable Importance plot
#plot(x = reg_logmu_avalon, n.var = 20)
#
#head(sort(reg_logmu_avalon$model.rf$variable.importance, decreasing = T), n=20)
#
## prediction error
#reg_logmu_avalon$model.rf$prediction.error
# 0.01524504
#
## error rate plot
#err.regAbcrf(object   = reg_logmu_avalon,
#             training = data.frame(logmu, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)
#
## oob predictions vs true values
# diagnostic plot
#plot(x    = logmu_avalon,
#     y    = reg_logmu_avalon$model.rf$predictions,
#     xlab = "True value",
#     ylab = "OOB predictions",
#     xlim = c(-10,-6),
#     ylim = c(-10,-6),
#     main = expression(log[10](italic(mu))),
#     cex.axis = 1.2,
#     cex.lab  = 1.2)
#abline(a=0, b=1, col = "green")
#
# manuscript plot
#df.logmu.ava <- data.frame(x = logmu_avalon,
#                            y = reg_logmu_avalon$model.rf$predictions)
#
#pdf(file="~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/oob_plots/reg_logmu_avalon.pdf", 
#    width=6, height=6)
#par(mar=c(5,5,4,1)+.1)
#hist2d(df.logmu.ava, nbins=70, 
#       col=viridis::viridis(32), 
#       FUN=function(x) log(length(x)),
#       xlab = expression(paste("true", " ", log[10](italic(mu)))),
#       ylab = expression(paste(log[10](italic(hat(mu))), " ","(OOB prediction)")),
#       xlim = c(-10,-7),
#       ylim = c(-10,-7),
#       cex.axis = 1.2,
#       cex.lab  = 1.2)
#abline(a=0, b=1, col = "black", lty = 3)
#dev.off()
```

#### Rho = Nr
```{r regression rho, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
#
#logrho_avalon <- log10(pooled_reftable_bees_avalon[, "meanNe2_Ava"] * pooled_reftable_bees_avalon[, "rr"])
#
#hist(logrho_avalon, freq = TRUE, xlab = expression(log[10](italic(rho))), main = "", col = "#bdbdbd")
#
## rf-regression
#reg_logrho_avalon <- regAbcrf(formula = logrho_avalon~.,
#                                 data = data.frame(logrho_avalon, global_sumstats4training_avalon),
#                                ntree = 1000,
#                                paral = T,
#                               ncores = 8)
#save(reg_logrho_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/reg_logrho_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/reg_logrho_avalon",".RData"))
#
#
## variable Importance plot
#plot(x = reg_logrho_avalon, n.var = 20)
#
#head(sort(reg_logrho_avalon$model.rf$variable.importance, decreasing = T), n=20)
#
## prediction error
#reg_logrho_avalon$model.rf$prediction.error
#  0.5835657
#
## error rate plot
#err.regAbcrf(object   = reg_logrho_avalon,
#             training = data.frame(logrho_avalon, global_sumstats4training_avalon),
#             paral    = T,
#             ncores   = 28)
#
## oob predictions vs true values
# diagnostic plot
#plot(x    = logrho_avalon,
#     y    = reg_logrho_avalon$model.rf$predictions, 
#     xlab = "True value",
#     ylab = "OOB predictions",
#     xlim = c(-8,-2),
#     ylim = c(-8,-2),
#     main = expression(log[10](italic(rho))),
#     cex.axis = 1.2,
#     cex.lab  = 1.2)
#abline(a=0, b=1, col = "green")
#
# manuscript plot
#df.logrho.ava <- data.frame(x = logrho_avalon,
#                            y = reg_logrho_avalon$model.rf$predictions)
#
#pdf(file="~/My_repositories/Tracking-selection/results/pipeline_v6_bees/random_forests/regression/oob_plots/reg_logrho_avalon.pdf", 
#    width=6, height=6)
#par(mar=c(5,5,4,1)+.1)
#hist2d(df.logrho.ava, nbins=70, 
#       col=viridis::viridis(32), 
#       FUN=function(x) log(length(x)),
#       xlab = expression(paste("true", " ", log[10](italic(rho)))),
#       ylab = expression(paste(log[10](italic(hat(rho))), " ","(OOB prediction)")),
#       xlim = c(-8,-2),
#       ylim = c(-8,-2),
#       cex.axis = 1.2,
#       cex.lab  = 1.2)
#abline(a=0, b=1, col = "black", lty = 3)
#dev.off()
```

## Sampling period inference

### ABC-RF classification for selection: prediction

#### Classification based on the proportion of strongly selected mutations - POPPrStrongMSel: quasi-Neutral vs strong-Selection
```{r classification neutral selection, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------

## rf-classification
posterior_class_selection_avalon <- predict(object     = class_selection_avalon,
                                            obs        = global_Obssumstats_avalon[,-c(19,22,25,120)],
                                            training   = data.frame(selection_avalon_subset, gss_avalon_subset[,-c(19,22,25,120)]),
                                            ntree      = 1000,
                                            paral      = TRUE,
                                            paral.predict = TRUE,
                                            ncores     = 2)

#save(posterior_class_selection_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_class_selection_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_class_selection_avalon",".RData"))

#(posterior_class_selection_avalon)

### PLACERITA
###-----------------------------------------------------------

## rf-classification
posterior_class_selection_placerita <- predict(object  = class_selection_placerita,
                                            obs        = global_Obssumstats_placerita,
                                            training   = data.frame(selection_placerita_subset, gss_placerita_subset),
                                            ntree      = 1000,
                                            paral      = TRUE,
                                            paral.predict = TRUE,
                                            ncores     = 2)

#save(posterior_class_selection_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_class_selection_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_class_selection_placerita",".RData"))

#(posterior_class_selection_placerita)
```

### ABC-RF regression for selection: prediction

#### Average genetic load
```{r prediction genetic load, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------

posterior_averageGenLoad_avalon_2 <- predict(object     = reg_averageGenLoad_avalon_2,
                                             obs        = global_Obssumstats_avalon,
                                             training   = data.frame(logitaverageGenload_avalon, 
                                                                     global_sumstats4training_avalon_averageGenLoad),
                                             quantiles  = c(0.025,0.5,0.975),
                                             paral      = T,
                                             ncores     = 8,
                                             rf.weights = T)

#save(posterior_averageGenLoad_avalon_2, 
#    file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_averageGenLoad_avalon_2",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_averageGenLoad_avalon_2",".RData"))

(posterior_averageGenLoad_avalon_2)

inv.logit(posterior_averageGenLoad_avalon_2$expectation)
# 0.0003287941

inv.logit(posterior_averageGenLoad_avalon_2$med)
# 0.001006965

inv.logit(posterior_averageGenLoad_avalon_2$quantiles)
#     quantile=0.025 quantile=0.5 quantile=0.975
#     1.135275e-09  0.001006965      0.9639485

hist(x      = logitaverageGenload_avalon,
     breaks = seq(-22,6,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(logit(italic(L))),
     ylab   = "probability density",
     ylim   = c(0,0.2))
wtd.hist(x      = logitaverageGenload_avalon,
         breaks = seq(-22,6,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_averageGenLoad_avalon_2$weights)
abline(v=c(posterior_averageGenLoad_avalon_2$med,
           posterior_averageGenLoad_avalon_2$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------

posterior_averageGenLoad_placerita_2 <- predict(object     = reg_averageGenLoad_placerita_2,
                                                obs        = global_Obssumstats_placerita,
                                                training   = data.frame(logitaverageGenload_placerita, 
                                                                        global_sumstats4training_placerita_averageGenLoad),
                                                quantiles  = c(0.025,0.5,0.975),
                                                paral      = T,
                                                ncores     = 8,
                                                rf.weights = T)

#save(posterior_averageGenLoad_placerita_2, 
#    file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_averageGenLoad_placerita_2",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_averageGenLoad_placerita_2",".RData"))

(posterior_averageGenLoad_placerita_2)

inv.logit(posterior_averageGenLoad_placerita_2$expectation)
# 0.0008036347

inv.logit(posterior_averageGenLoad_placerita_2$med)
# 0.02585036

inv.logit(posterior_averageGenLoad_placerita_2$quantiles)
#     quantile=0.025 quantile=0.5 quantile=0.975
#      2.00562e-16   0.02585036      0.7557448

hist(x      = logitaverageGenload_placerita,
     breaks = seq(-37,7,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(logit(italic(L))),
     ylab   = "probability density",
     ylim   = c(0,0.2))
wtd.hist(x      = logitaverageGenload_placerita,
         breaks = seq(-37,7,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_averageGenLoad_placerita_2$weights)
abline(v=c(posterior_averageGenLoad_placerita_2$med,
           posterior_averageGenLoad_placerita_2$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Proportion of strongly selected mutations - POPPrStrongMSel
```{r prediction strongly selected, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logitpopstrongmsel_avalon <- predict(object = reg_logitpopstrongmsel_avalon,
                                               obs        = global_Obssumstats_avalon,
                                               training   = data.frame(logitpopstrongmsel_avalon, 
                                                                       global_sumstats4training_avalon_popstrongmsel),
                                               quantiles  = c(0.025,0.5,0.975),
                                               paral      = T,
                                               ncores     = 8,
                                               rf.weights = T)


#save(posterior_logitpopstrongmsel_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logitpopstrongmsel_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logitpopstrongmsel_avalon",".RData"))

(posterior_logitpopstrongmsel_avalon)

inv.logit(posterior_logitpopstrongmsel_avalon$expectation)
# 2.313233e-05

inv.logit(posterior_logitpopstrongmsel_avalon$med)
# 1.478457e-05

inv.logit(posterior_logitpopstrongmsel_avalon$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   1.446044e-06 1.478457e-05    0.001043491

hist(x      = logitpopstrongmsel_avalon,
     breaks = seq(-17,1,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(logit(italic(P))),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logitpopstrongmsel_avalon,
         breaks = seq(-16,1,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logitpopstrongmsel_avalon$weights)
abline(v=c(posterior_logitpopstrongmsel_avalon$med,
           posterior_logitpopstrongmsel_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logitpopstrongmsel_placerita <- predict(object = reg_logitpopstrongmsel_placerita,
                                               obs        = global_Obssumstats_placerita,
                                               training   = data.frame(logitpopstrongmsel_placerita, 
                                                                       global_sumstats4training_placerita_popstrongmsel),
                                               quantiles  = c(0.025,0.5,0.975),
                                               paral      = T,
                                               ncores     = 8,
                                               rf.weights = T)


#save(posterior_logitpopstrongmsel_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logitpopstrongmsel_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logitpopstrongmsel_placerita",".RData"))

(posterior_logitpopstrongmsel_placerita)

inv.logit(posterior_logitpopstrongmsel_placerita$expectation)
# 0.0001262504

inv.logit(posterior_logitpopstrongmsel_placerita$med)
# 9.385836e-05

inv.logit(posterior_logitpopstrongmsel_placerita$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   4.896278e-06 9.385836e-05      0.4931064

hist(x      = logitpopstrongmsel_placerita,
     breaks = seq(-14,2,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(logit(italic(P))),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logitpopstrongmsel_placerita,
         breaks = seq(-14,2,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logitpopstrongmsel_placerita$weights)
abline(v=c(posterior_logitpopstrongmsel_placerita$med,
           posterior_logitpopstrongmsel_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Theta - selected mutations
```{r prediction thetaPS, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logthetaPS_avalon <- predict(object     = reg_logthetaPS_avalon,
                                       obs        = global_Obssumstats_avalon,
                                       training   = data.frame(logthetaPS_ava, global_sumstats4training_avalon),
                                       quantiles  = c(0.025,0.5,0.975),
                                       paral      = T,
                                       ncores     = 8,
                                       rf.weights = T)
#save(posterior_logthetaPS_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logthetaPS_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logthetaPS_avalon",".RData"))

(posterior_logthetaPS_avalon)

10^(posterior_logthetaPS_avalon$expectation)
# 0.5887578

10^(posterior_logthetaPS_avalon$med)
# 0.3723123

10^(posterior_logthetaPS_avalon$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   0.0001716364    0.3723123       5661.326

hist(x      = logthetaPS_ava,
     breaks = seq(-7,6,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(θ) * italic(P)[S])),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logthetaPS_ava,
         breaks = seq(-7,6,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logthetaPS_avalon$weights)
abline(v=c(posterior_logthetaPS_avalon$med,
           posterior_logthetaPS_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logthetaPS_placerita <- predict(object     = reg_logthetaPS_placerita,
                                       obs        = global_Obssumstats_placerita,
                                       training   = data.frame(logthetaPS_pla, global_sumstats4training_placerita),
                                       quantiles  = c(0.025,0.5,0.975),
                                       paral      = T,
                                       ncores     = 8,
                                       rf.weights = T)
#save(posterior_logthetaPS_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logthetaPS_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logthetaPS_placerita",".RData"))

(posterior_logthetaPS_placerita)

10^(posterior_logthetaPS_placerita$expectation)
# 5.810177

10^(posterior_logthetaPS_placerita$med)
# 6.224624

10^(posterior_logthetaPS_placerita$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   0.01295718     6.224624       16957.88

hist(x      = logthetaPS_pla,
     breaks = seq(-7,6,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(θ) * italic(P)[S])),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logthetaPS_pla,
         breaks = seq(-7,6,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logthetaPS_placerita$weights)
abline(v=c(posterior_logthetaPS_placerita$med,
           posterior_logthetaPS_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Ns
```{r prediction Ns, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logNs_avalon <- predict(object     = reg_logNs_avalon,
                                  obs        = global_Obssumstats_avalon,
                                  training   = data.frame(logNs_ava, global_sumstats4training_avalon),
                                  quantiles  = c(0.025,0.5,0.975),
                                  paral      = T,
                                  ncores     = 8,
                                  rf.weights = T)

#save(posterior_logNs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logNs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logNs_avalon",".RData"))

(posterior_logNs_avalon)

10^(posterior_logNs_avalon$expectation)
# 0.846396

10^(posterior_logNs_avalon$med)
# 0.6348757

10^(posterior_logNs_avalon$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   0.02535777    0.6348757       56.33912

hist(x      = logNs_ava,
     breaks = seq(-3,4,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[e] * italic(s))),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logNs_ava,
         breaks = seq(-3,4,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logNs_avalon$weights)
abline(v=c(posterior_logNs_avalon$med,
           posterior_logNs_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logNs_placerita <- predict(object     = reg_logNs_placerita,
                                  obs        = global_Obssumstats_placerita,
                                  training   = data.frame(logNs_pla, global_sumstats4training_placerita),
                                  quantiles  = c(0.025,0.5,0.975),
                                  paral      = T,
                                  ncores     = 8,
                                  rf.weights = T)

#save(posterior_logNs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logNs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logNs_placerita",".RData"))

(posterior_logNs_placerita)

10^(posterior_logNs_placerita$expectation)
# 3.254165

10^(posterior_logNs_placerita$med)
# 2.564882

10^(posterior_logNs_placerita$quantiles)
#quantile=0.025 quantile=0.5 quantile=0.975
#   0.07202465     2.564882       373.5629

hist(x      = logNs_pla,
     breaks = seq(-3,4,0.5),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[e] * italic(s))),
     ylab   = "probability density",
     ylim   = c(0,0.5))
wtd.hist(x      = logNs_pla,
         breaks = seq(-3,4,0.5),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logNs_placerita$weights)
abline(v=c(posterior_logNs_placerita$med,
           posterior_logNs_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

### ABC-RF regression for demography: prediction

#### Harmonic mean of the effective population sizes of period 2 - meanNe2
```{r prediction MeanNe2, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logmeanNe2_avalon <- predict(object     = reg_logmeanNe2_avalon,
                                       obs        = global_Obssumstats_avalon,
                                       training   = data.frame(logmeanNe2_ava, global_sumstats4training_avalon),
                                       quantiles  = c(0.025,0.5,0.975),
                                       paral      = T,
                                       ncores     = 8,
                                       rf.weights = T)


#save(posterior_logmeanNe2_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2_avalon",".RData"))

(posterior_logmeanNe2_avalon)

10^(posterior_logmeanNe2_avalon$expectation)
# 100.8206

10^(posterior_logmeanNe2_avalon$med)
# 82.98198

10^(posterior_logmeanNe2_avalon$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       22.05633     82.98198       958.5587

hist(x      = logmeanNe2_ava,
     breaks = seq(-2,5,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[e])),
     ylab   = "probability density",
     ylim   = c(0,2.0))
wtd.hist(x      = logmeanNe2_ava,
         breaks = seq(-2,5,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logmeanNe2_avalon$weights)
abline(v=c(posterior_logmeanNe2_avalon$med,
           posterior_logmeanNe2_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

## comparison with FST-based Ne estimates
##---------------------------------------------------
fstne2_avalon <- globalFSTNe(x=global_Obssumstats_avalon$GSS_WCst_Ava, tau=104)
# 68.41245

# RMSE
sqrt(mean((fstne2_avalon - posterior_logmeanNe2_avalon$med)^2, na.rm = T))
# 66.49347

### PLACERITA
###-----------------------------------------------------------
posterior_logmeanNe2_placerita <- predict(object     = reg_logmeanNe2_placerita,
                                       obs        = global_Obssumstats_placerita,
                                       training   = data.frame(logmeanNe2_pla, global_sumstats4training_placerita),
                                       quantiles  = c(0.025,0.5,0.975),
                                       paral      = T,
                                       ncores     = 8,
                                       rf.weights = T)


#save(posterior_logmeanNe2_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2_placerita",".RData"))

(posterior_logmeanNe2_placerita)

10^(posterior_logmeanNe2_placerita$expectation)
# 143.6135

10^(posterior_logmeanNe2_placerita$med)
# 146.0324

10^(posterior_logmeanNe2_placerita$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       4.57491     146.0324       1145.739

hist(x      = logmeanNe2_pla,
     breaks = seq(-1,5,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[e])),
     ylab   = "probability density",
     ylim   = c(0,2.0))
wtd.hist(x      = logmeanNe2_pla,
         breaks = seq(-1,5,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logmeanNe2_placerita$weights)
abline(v=c(posterior_logmeanNe2_placerita$med,
           posterior_logmeanNe2_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

## comparison with FST-based Ne estimates
##---------------------------------------------------
fstne2_placerita <- globalFSTNe(x=global_Obssumstats_placerita$GSS_WCst_Pla, tau=15)
# 67.77758

# RMSE
sqrt(mean((fstne2_placerita - posterior_logmeanNe2_placerita$med)^2, na.rm = T))
# 65.61313
```

#### Population size of period 2 - census size Ncs
```{r predition Ncs, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logncs_avalon <- predict(object     = reg_logncs_avalon,
                                  obs        = global_Obssumstats_avalon,
                                  training   = data.frame(logncs_ava, global_sumstats4training_avalon),
                                  quantiles  = c(0.025,0.5,0.975),
                                  paral      = T,
                                  ncores     = 8,
                                  rf.weights = T)

#save(posterior_logncs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logncs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logncs_avalon",".RData"))

(posterior_logncs_avalon)

10^(posterior_logncs_avalon$expectation)
# 134.9649

10^(posterior_logncs_avalon$med)
# 81

10^(posterior_logncs_avalon$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       17           81       5359.332

hist(x      = logncs_ava,
     breaks = seq(0,4.0,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[cs])),
     ylab   = "probability density",
     ylim   = c(0,2.0))
wtd.hist(x      = logncs_ava,
         breaks = seq(0,4,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logncs_avalon$weights)
abline(v=c(posterior_logncs_avalon$med,
           posterior_logncs_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logncs_placerita <- predict(object     = reg_logncs_placerita,
                                  obs        = global_Obssumstats_placerita,
                                  training   = data.frame(logncs_pla, global_sumstats4training_placerita),
                                  quantiles  = c(0.025,0.5,0.975),
                                  paral      = T,
                                  ncores     = 8,
                                  rf.weights = T)

#save(posterior_logncs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logncs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logncs_placerita",".RData"))

(posterior_logncs_placerita)

10^(posterior_logncs_placerita$expectation)
# 162.5695

10^(posterior_logncs_placerita$med)
# 139

10^(posterior_logncs_placerita$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       14          139       4691.664

hist(x      = logncs_pla,
     breaks = seq(0,4.0,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(N)[cs])),
     ylab   = "probability density",
     ylim   = c(0,2.0))
wtd.hist(x      = logncs_pla,
         breaks = seq(0,4,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logncs_placerita$weights)
abline(v=c(posterior_logncs_placerita$med,
           posterior_logncs_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Ratio Mean effective size / population size of period 2 - MeanNe2/Ncs
```{r predition MeanNe2Ncs, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logmeanNe2ncs_avalon <- predict(object     = reg_logmeanNe2ncs_avalon,
                                          obs        = global_Obssumstats_avalon,
                                          training   = data.frame(logmeanNe2ncs_ava, global_sumstats4training_avalon),
                                          quantiles  = c(0.025,0.5,0.975),
                                          paral      = T,
                                          ncores     = 8,
                                          rf.weights = T)

#save(posterior_logmeanNe2ncs_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2ncs_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2ncs_avalon",".RData"))

(posterior_logmeanNe2ncs_avalon)

10^(posterior_logmeanNe2ncs_avalon$expectation)
# 0.4496165

10^(posterior_logmeanNe2ncs_avalon$med)
# 0.9067546

10^(posterior_logmeanNe2ncs_avalon$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       0.001153188    0.9067546       1.128161

hist(x      = logmeanNe2ncs_ava,
     breaks = seq(-6,1,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(italic(N)[e]/italic(N)[cs]),
     ylab   = "probability density",
     ylim   = c(0,4.0))
wtd.hist(x      = logmeanNe2ncs_ava,
         breaks = seq(-6,1,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logmeanNe2ncs_avalon$weights)
abline(v=c(posterior_logmeanNe2ncs_avalon$med,
           posterior_logmeanNe2ncs_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logmeanNe2ncs_placerita <- predict(object     = reg_logmeanNe2ncs_placerita,
                                          obs        = global_Obssumstats_placerita,
                                          training   = data.frame(logmeanNe2ncs_pla, global_sumstats4training_placerita),
                                          quantiles  = c(0.025,0.5,0.975),
                                          paral      = T,
                                          ncores     = 8,
                                          rf.weights = T)

#save(posterior_logmeanNe2ncs_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2ncs_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmeanNe2ncs_placerita",".RData"))

(posterior_logmeanNe2ncs_placerita)

10^(posterior_logmeanNe2ncs_placerita$expectation)
# 0.9200547

10^(posterior_logmeanNe2ncs_placerita$med)
# 1.059399

10^(posterior_logmeanNe2ncs_placerita$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       0.2440719     1.059399       1.144462

hist(x      = logmeanNe2ncs_pla,
     breaks = seq(-4,1,0.2),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(italic(N)[e]/italic(N)[cs]),
     ylab   = "probability density",
     ylim   = c(0,4.0))
wtd.hist(x      = logmeanNe2ncs_pla,
         breaks = seq(-4,1,0.2),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logmeanNe2ncs_placerita$weights)
abline(v=c(posterior_logmeanNe2ncs_placerita$med,
           posterior_logmeanNe2ncs_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Theta of period 2
```{r predition Theta2, echo=TRUE, eval=FALSE, include=TRUE}

### AVALON
###-----------------------------------------------------------
posterior_logtheta2_avalon <- predict(object     = reg_logtheta2_avalon,
                                      obs        = global_Obssumstats_avalon,
                                      training   = data.frame(logtheta2_ava, global_sumstats4training_avalon),
                                      quantiles  = c(0.025,0.5,0.975),
                                      paral      = T,
                                      ncores     = 8,
                                      rf.weights = T)

#save(posterior_logtheta2_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logtheta2_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logtheta2_avalon",".RData"))

(posterior_logtheta2_avalon)

10^(posterior_logtheta2_avalon$expectation)
# 2420.534

10^(posterior_logtheta2_avalon$med)
# 1925.017

10^(posterior_logtheta2_avalon$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       131.1239     1925.017       54793.19

hist(x      = logtheta2_ava,
     breaks = seq(-1,6,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(θ))),
     ylab   = "probability density",
     ylim   = c(0,1.5))
wtd.hist(x      = logtheta2_ava,
         breaks = seq(-1,6,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logtheta2_avalon$weights)
abline(v=c(posterior_logtheta2_avalon$med,
           posterior_logtheta2_avalon$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))

### PLACERITA
###-----------------------------------------------------------
posterior_logtheta2_placerita <- predict(object     = reg_logtheta2_placerita,
                                      obs        = global_Obssumstats_placerita,
                                      training   = data.frame(logtheta2_pla, global_sumstats4training_placerita),
                                      quantiles  = c(0.025,0.5,0.975),
                                      paral      = T,
                                      ncores     = 8,
                                      rf.weights = T)

#save(posterior_logtheta2_placerita, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logtheta2_placerita",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logtheta2_placerita",".RData"))

(posterior_logtheta2_placerita)

10^(posterior_logtheta2_placerita$expectation)
# 32191.51

10^(posterior_logtheta2_placerita$med)
# 29545.17

10^(posterior_logtheta2_placerita$quantiles)
# quantile=0.025 quantile=0.5 quantile=0.975
#       5355.317     29545.17         171315

hist(x      = logtheta2_pla,
     breaks = seq(-1,6,0.1),
     col    = "#969696",
     freq   = FALSE,
     main   = "",
     xlab   = expression(log[10](italic(θ))),
     ylab   = "probability density",
     ylim   = c(0,1.5))
wtd.hist(x      = logtheta2_pla,
         breaks = seq(-1,6,0.1),
         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
         weight = posterior_logtheta2_placerita$weights)
abline(v=c(posterior_logtheta2_placerita$med,
           posterior_logtheta2_placerita$quantiles[c(1,3)]),
       col="red",
       lty=c(1,3,3))
```

#### Per site mutation rate mu
```{r predition site mutation rate, echo=TRUE, eval=FALSE, include=TRUE}
### AVALON
###-----------------------------------------------------------
#
#posterior_logmu_avalon <- predict(object     = reg_logmu_avalon,
#                                  obs        = global_Obssumstats_avalon,
#                                  training   = data.frame(logmu_avalon, global_sumstats4training_avalon),
#                                  quantiles  = c(0.025,0.5,0.975),
#                                  paral      = T,
#                                  ncores     = 8,
#                                  rf.weights = T)
#
#
#save(posterior_logmu_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmu_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logmu_avalon",".RData"))
#
#(posterior_logmu_avalon)
#
#hist(x      = logmu_avalon,
#     breaks = seq(-10,-6,0.1),
#     col    = "#969696",
#     freq   = FALSE,
#     main   = "",
#     xlab   = expression(log[10](italic(mu))),
#     ylab   = "probability density",
#     ylim   = c(0,2.0))
#wtd.hist(x      = logmu_avalon,
#         breaks = seq(-10,-6,0.1),
#         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
#         weight = posterior_logmu_avalon$weights)
```

#### Rho = Nr
```{r predition site mutation rate, echo=TRUE, eval=FALSE, include=TRUE}
### AVALON
###-----------------------------------------------------------
#posterior_logrho_avalon <- predict(object     = reg_logrho_avalon,
#                                  obs        = global_Obssumstats_avalon,
#                                  training   = data.frame(logrho_avalon, global_sumstats4training_avalon),
#                                  quantiles  = c(0.025,0.5,0.975),
#                                  paral      = T,
#                                  ncores     = 8,
#                                  rf.weights = T)
#
#
#save(posterior_logrho_avalon, 
#     file = paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logrho_avalon",".RData"))
#load(file=paste0("~/My_repositories/Tracking-selection/results/pipeline_v6_bees/posterior_obs/posterior_logrho_avalon",".RData"))
#
#(posterior_logrho_avalon)
#
#hist(x      = logrho_avalon,
#     #breaks = seq(-10,-7,0.1),
#     col    = "#969696",
#     freq   = FALSE,
#     main   = "",
#     xlab   = expression(log[10](italic(rho))),
#     ylab   = "probability density",
#     ylim   = c(0,1.0))
#wtd.hist(x      = logrho_avalon,
#         #breaks = seq(-10,-7,0.1),
#         col    = adjustcolor( "#41b6c4", alpha.f = 0.5), freq=FALSE, add=TRUE,
#         weight = posterior_logrho_avalon$weights)
```
